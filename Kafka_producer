acks =all
need to use min.insync.replica ( If set at broker level, can be overriden at topic level)
min.insync.replica = 2 , means atleast two isr ( including leader ) should give acks saying they have the message

if replication.factor = 3, min.insync.replica = 2, acks = all, Only tolerate one broker going down.
Otherwise producer throws acknowledgement

retries is always a high number. // default Integer.MAX_VALUE
but has a upper limit of delivery.timeout.ms // default 2 mins

max.in.flight.requests.per.connection = 5 
Max number of producer connections that can be made to broker. IF errr and retry happen it can be out of order.
Retrying messages can put them ou of order
To make sure it's ordered set connection to = 1// But , peformance gone.





acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

  Idempotent Producer

produce.request.id, used to detect duplicates
retries = max,
request.inflight = 5
acks=all

propducerconfig.put("enable_idempotence", "true")

// Message compressions

Compress data to decrease the disk load. More cpu cycles are used to compression and decompression

compression.type = gzip, lz4, snappy
Bigger the batch, better compression

// Batching 
linger.ms, default 0 ( number of milliseconds a producer is willing to wait before it sends a batch out)
// Default = 16kb
batch.size is reached, max size of bytes to be included in one message

if batch.size is reached before linger.ms is over, then send the message

any message bigger than batch size will be not batched

batch.size is per parition // Get batch size metrics using Kafka Producer metrics

// Key hashing
Converted into binary and then hashed
Using murmur2 algo. 

targetPartion = Utils.abs(murmur2(record.key())) % totalPartitions

.send() method will start to block if producer buffer is filled up.
If will block for 60 seconds, if not able to send then it will throw Exception

Max.block.ms : 60 seconds // default

// Settings when producer produces too fast, and broker can't handle so much data at a point
buffer.memory: 32MB default

Reasons: 
Producer has filled up too fast
Broker not accepting any data
60 seconds is up


Customer(msisdn=1833837391, firstName=Abdul, lastName=Karim, customerMetas=[CustomerMeta(metaKey=LANGUAGE, customerId=1412001937940242432, metaValue=ENGLISH, metaDataType=String), CustomerMeta(metaKey=MOBILE_CONNECTION_TYPE, customerId=1412001937940242432, metaValue=PREPAID, metaDataType=String), CustomerMeta(metaKey=NATIONALITY, customerId=1412001937940242432, metaValue=, metaDataType=String), CustomerMeta(metaKey=OCCUPATION_CATEGORY, customerId=1412001937940242432, metaValue=, metaDataType=String), CustomerMeta(metaKey=DOB, customerId=1412001937940242432, metaValue=, metaDataType=LocalDate), CustomerMeta(metaKey=GENDER, customerId=1412001937940242432, metaValue=MALE, metaDataType=String), CustomerMeta(metaKey=OCCUPATION, customerId=1412001937940242432, metaValue=, metaDataType=String), CustomerMeta(metaKey=NID, customerId=1412001937940242432, metaValue=7676767676655, metaDataType=String), CustomerMeta(metaKey=YEAR_OF_BIRTH, customerId=1412001937940242432, metaValue=1966, metaDataType=Integer), CustomerMeta(metaKey=EMAIL, customerId=1412001937940242432, metaValue=adf@yi.com, metaDataType=String)], customerAddress=CustomerAddress(customerId=1412001937940242432, address=76 Shivaji Marg 
 , latitude=, longitude=, city=), emergencyContactFirstName=, emergencyContactLastName=, emergencyContactNumber=, emergencyContactCity=, emergencyContactAddress=, emergencyCustomerId=, creationSource=SELF)