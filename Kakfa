// Kafka version > use --bootstrap-server localhost:2181 instead of zookeeper option
// To edit default creation of topics, edit server.properties file
// Log Basics

Download Kafka

You need atleast 4gb of space

Step 1: Download the code
Download the 1.1.0 release and un-tar it.

link = http://www-us.apache.org/dist/kafka/1.1.0/kafka_2.11-1.1.0.tgz
 
tar -xzf kafka_2.11-1.1.0.tgz
cd kafka_2.11-1.1.0


Step 2: Start the server
Go into your Kafka folder and then run it.
Kafka uses ZooKeeper so you need to first start a ZooKeeper server if you don't already have one. You can use the convenience script packaged with kafka to get a quick-and-dirty single-node ZooKeeper instance.

bin/zookeeper-server-start.sh config/zookeeper.properties


Now start the Kafka server:

 bin/kafka-server-start.sh config/server.properties

//Create topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test

//See	ll topics
bin/kafka-topics.sh --list --zookeeper localhost:2181

//See messages of a topic
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

//Send message
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test

//Delete topic
bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic <Topic Name>

bin/kafka-topics.sh --describe --topic bangladesh-bkash-reconciliation --bootstrap-server localhost:9092

kafka-topics --bootstrap-server [BROKER_HOST]:[PORT] --describe


bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic srilanka-s2ms-notification-deduction

// KAFKA_V2

Topic: 

Similar to table in database, identified by name.
Spilt into partitions 
0 to n partitions
Within each partition , each message will have an incremental id called the offet
Offsets
P0 : 0, 1, 2, 
P1  : 0, 1, 2, 3, 4, 5
P2 : 0, 1,

Offset only has meaning with the partition

P0-0 !== P1-0
Order is only maintained withint a partition
P0-0, written before P0-1
and not P1-1 not before P0-0
Once data is written to an offset, it can't be updated etc

One leader for each parition at one point of time.
and multiple ISR (in sync replica)

Producer :
Acknowledgement comes from the broker
Acks
0: Producer just sends data, no ack. (possibility of data loss)
1: Producer waita for leader to ack. (Default)
all: Leader + replications returns acknowledgement (no data loss)

Keys : Same key will always go to same parition, Truck_gps example.
Based on key hashing, depends on number of paritions etc etc

Consumer: 

Reads based on topic-parition-offset.
Order not maintained parition wise. 
But order maintained within paritions

Each consumer inside a consumer group reads from an exclusive partitions

Topic-1-P0   Topic-1-P1     Topic-1-P2

c-group-app-1       c-group-app-2        c-group-app-3
c1 c2                 c1 c2 c3             c1

c-group-app-1
c1 only reads from p0, p1
c2 only reads from p2

c-group-app-2
c1 only reads from p0, 
c2 only reads from p1,
c3 only reads from p2

c-group-app-3
c1 only reads from p0, p1, p2

Consumer offsets notes live in kafka
Sored in topic <Topic_name>__consumer_offset
Commiting the offset means writing to the above topic

Consumer when to commit: 

Delivery semantics :

At most once : offsets are commited as soon as messsage is received. If something goes wrong message won't be read again

At least once : commit offset, after reading and doing something with the data. If processing goes wrong message will be read again.
Same message can be processed again and again

Exactly once


Brokers
All brokers have info about the cluster.
Client connects to broker, and does a metadata request and sends the client list of all brokers 
So client can push to any broker


// Topic creation 
1) bin/kafka-topics.sh --zookeeper localhost:2181 --topic first-topic --create --partitions 3 --replication-factor 1
Cannot create topic with replication factor more than number of brokers


Topic: first-topic	PartitionCount: 3	ReplicationFactor: 1	Configs: 
	Topic: first-topic	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
	Topic: first-topic	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
	Topic: first-topic	Partition: 2	Leader: 0	Replicas: 0	Isr: 0


in Replicas and isr, it's the id of the broker it's replicated in

//Producer 

bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first-topic

producing to a new topic which is not created, causes error in first time. The producer waits until leader is availible and then pushes it again

//Consumer
console consumer does not read old messages just reads the new ones

// Read from beginign
 bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first-topic --from-beginning
 --group to specify which group

 when you start console consumer and don't specify group, it generates a random group. Not there after kafka 2.1

 // Group View

 bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-second-app

 eg: 

 GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
my-third-app    first-topic     1          5               5               0               -               -               -
my-third-app    first-topic     0          8               9               1               -               -               -
my-third-app    first-topic     2          7               7               0               -               -               -

LOG-END-OFFSET : offset of th latest message in that parition of that topic, lag is basically the diff

//Shifting offsets back 
--to-earliest read from first option
// Partitions can be specified using topic:0 format
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --reset-offsets --shift-by -2 --group my-third-app --topic first-topic --execute



// Commands 
Producer with keys

kafka-console-producer --broker-list 127.0.0.1:9092 --topic first_topic --property parse.key=true --property key.separator=,
> key,value
> another key,another value
Consumer with keys

kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning --property print.key=true --property key.separator=,


Consumer.assingn(String topic, int partition);
Consumer.seek(int offset)


// Configuration 
https://kafka.apache.org/documentation/#producerconfigs
https://kafka.apache.org/documentation/#consumerconfigs
https://kafka.apache.org/documentation/#brokerconfigs

// Broker and paritions
brokers < 6 
paritins 2 * brokers 
incase number of brokers increases, each broker still has something to do

brokers > 12 ,
1 per broker

number of paritions === consumer count


kafka-topics

// --delete-config
bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name configured-topic --alter --add-config min.insync.replicas=2


